\documentclass{article}

\title{Education Project}
\author{Jared Wilber, Shannon Chang, Noura Kawa, Manuel Horta}
\date{\today}


\begin{document}
\SweaveOpts{concordance=TRUE}


\begin{abstract}
Absstract goes here. 
\end{abstract}

\section{Introduction}

Our Question: A minority-focused NGO wants to donate money to schools in an effort to help increase minority success. In order to do this, they need to identify those schools that "underserve" minority students. As they may have multiple schools in consideration, they'd also like a way to determine which of the underserving schools deserves funding.This is where we come in. We do the following:

\begin{itemize}
      \item Determine which universities "underserve" minorities (XGBOOST)
      \item Using a created BESTVALUE metric, rank universities based on how "good" they are.
\end{itemize}
\bigbreak

Thus, the NGO can employ us in the following 2 ways:

\begin{enumerate}
\item Given a school, predict whether or not it will underserve or overserves minorities (XGBOOST). 
\item Given multiple minority serving schools, determine which should give funding (BEST VALUE METRIC).
\end{enumerate}



Summary of our value: Given a list of schools, determine which schools underserve minorities. From these schools, rank them based on value.

\section{Analysis}

Our analysis consists of two primary objectives:
\begin{enumerate}
  \item Define model used to predict minority serving (XG-BOOST)
  \item Define metric used to rank schools (BEST VALUE RANKING)
\end{enumerate}  

\textbf{Train XG-Boost model}
Describe process (split into train/test, one-hot encoding, make numeric, etc.)
Return Model Accuracy

\medbreak

\textbf{Ranking schools}
Describe BEST VALUE metric. We used lasso/xgboost feature importance to find the variables that US NEWS uses, then made a metric similar to theirs. After this, we ranked out data.
         


\subsection{Data}

Because of fluctuations in data and the low volatility in year-to-year things (red-tape etc.), we opted to use the most recent dataset. In this way, we have access to more useful variables and also have a data set that is more likely to reflect present day. 
\medbreak
We want to identify those schools that overserve or underserve minorities. Our dataset lives in very high dimensions, so our first order of business is to reduce the dimensionality. This is important because the NGO would like to understand our methods, so our model must be interpretable. We broke this up into 4 steps:

\begin{enumerate}
  \item Hand-select important features from data. This yielded about 500 variables.
  \item Create our own variables, including BEST VALUE metric
  \item From these variables, we needed to select variables that were related to minorities. We determined these variables with FEATURE IMPORTANCE (LASSO/XGBOOST).
  \item Remove correlated variables
\end{enumerate}

Step 1 of the above is self-explanatory and we selected the following variables (column names):
\medbreak
\textbf{Variable names:}

\medbreak
Step 2 of the above is more involved. To create BEST VALUE, we first scraped the wh\_post (Washignton Post best school rankings)
for rankings. Once we had our ranked schools and appended them to our dataset, we used \linebreak LASSO/XGBOOST to pick those features that 
were associated with a school being ranked (we treat this as a proxy for quality). We then used these variables to build a BEST-VALUE metric.

insert feature importance


\medbreak
For step 3, we computed another feature importance metric, this time with our response being the minority served classification. We get rid of variables that don't contribute to our model. Because we are predicting discrete categories of minority serving, we use xgboost for feature importance.

insert feature importance 2 plot

\medbreak
Step 4 is to check for correlated variables and to remove them as well.

insert correlation plot

\medbreak
Finally, we have our dataset. Now our dataset is much smaller \textbf{and} more relevant to our goals. Thus, our data is less computationally expensive, has higher predictable power, and is more interpretable.
        
discuss new data

\subsection{Exploratory Data Analysis}


------ EDA------
        
  Plot ideas: What they reveal
      - PCA
      - T-sne
      - FEATURE PLOT
      
---- end eda ----


\section{Results}

Show the above in action

feature importance
xgboost - find values for minorities, use them in model
bestvalue metric - use coefficient values from lasso on ranking to get weights + relevant columns


\section{Conclusions}
- Model accuracy
- whatever else


\end{document}